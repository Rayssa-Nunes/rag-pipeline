{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyODuFG9eLhYQYd8eQmaHzBS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A6qdLpLLSrUA"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers einops accelerate bitsandbytes\n",
        "!pip install -q langchain langchain_community langchain-huggingface langchainhub langchain_chroma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        ")\n",
        "\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "LR_1KdwuY0Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_TOKEN\"] = getpass.getpass()"
      ],
      "metadata": {
        "id": "godlkkbdceNK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregando a LLM"
      ],
      "metadata": {
        "id": "oUS54RIZcvbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    device_map='auto',\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task='text-generation',\n",
        "    max_new_tokens=500,\n",
        "    temperature=0.1,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=False,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "a2jCtRCxaUzg",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Template e Chain"
      ],
      "metadata": {
        "id": "WoR0yiUyc1DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "<|begin_of_text|>\n",
        "<|start_header_id|>system<|end_header_id|>\n",
        "Você é um assistente virtual prestativo e está respndendo pergunts gerais.\n",
        "<|eot_id|>\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "{pergunta}\n",
        "<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt"
      ],
      "metadata": {
        "id": "Jye0ZhXrc2my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm\n",
        "chain.invoke({'pergunta': 'Que dia é hoje?'})"
      ],
      "metadata": {
        "id": "cTyVUAmahDF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt para RAG\n",
        "\n",
        "prompt base: https://smith.langchain.com/hub/rlm/rag-prompt"
      ],
      "metadata": {
        "id": "vz3Qk-oLhbbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_rag = '''\n",
        "<|begin_of_text|>\n",
        "<|start_header_id|>system<|end_header_id|>\n",
        "Você é um assistente virtual prestativo e está respondendo perguntas gerais.\n",
        "Use os seguintes pedaços de contexto recuperado para responder à pergunta.\n",
        "Se você não sabe a resposta, apenas diga que não sabe. Mantenha a respsta concisa.\n",
        "<|eot_id|>\n",
        "<|start_header_id|>user<|end_header_id|>\n",
        "Pergunta: {pergunta}\n",
        "Contexto: {contexto}\n",
        "<|eot_id|>\n",
        "<|start_header_id|>assistant<|end_header_id|>\n",
        "'''"
      ],
      "metadata": {
        "id": "BfQoPq80ic0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_rag = PromptTemplate.from_template(template_rag)\n",
        "prompt_rag"
      ],
      "metadata": {
        "id": "cNAexL0IjLlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definindo contexto"
      ],
      "metadata": {
        "id": "HKpZb3o1hxt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "dia = date.today()\n",
        "dia"
      ],
      "metadata": {
        "id": "v20i1Tdlhwov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contexto = f'Você sabe que hoje é dia {dia}'\n",
        "print(contexto)"
      ],
      "metadata": {
        "id": "3aUOg88QjeOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação da Chain / Geração"
      ],
      "metadata": {
        "id": "WIPL7taOh2y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Em casos de alucinação: Responda a pergunta com base apenas no contexto\n",
        "chain_rag = prompt_rag | llm | StrOutputParser()\n",
        "pergunta = 'Que dia é hoje? Retorne a data em formato dd/mm/yyyy'\n",
        "\n",
        "chain_rag.invoke({'pergunta': pergunta, 'contexto': contexto})"
      ],
      "metadata": {
        "id": "BVcR8HWWjq4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_rag"
      ],
      "metadata": {
        "id": "6TIB9zwLlfZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_rag = prompt_rag | llm | StrOutputParser()\n",
        "\n",
        "contexto = '''\n",
        "Faturamento trimestral:\n",
        "1º: R$42476,40\n",
        "2º: R$46212,97\n",
        "3º: R$41324,56\n",
        "4º: R$56430,24\n",
        "'''\n",
        "pergunta = 'Qual trimestre teve o maior faturamento?'\n",
        "\n",
        "chain_rag.invoke({'pergunta': pergunta, 'contexto': contexto})"
      ],
      "metadata": {
        "id": "GjznA3oVh4xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Depuração / Debugging\n",
        "\n"
      ],
      "metadata": {
        "id": "Eh4nQ-I2lfrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_debug\n",
        "set_debug(True)"
      ],
      "metadata": {
        "id": "7tzmZMfQqPJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pergunta = 'Qual trimestre teve o menor faturamento?'\n",
        "\n",
        "chain_rag.invoke({'pergunta': pergunta, 'contexto': contexto})"
      ],
      "metadata": {
        "id": "LVxa2K6TqyIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_debug(False)"
      ],
      "metadata": {
        "id": "YMr-R9tir9Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicação para RAG com contextos maiores"
      ],
      "metadata": {
        "id": "-jLNGAoJuNfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapas de Indexação"
      ],
      "metadata": {
        "id": "eo9BM7k6uU74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1 - Carregar o conteúdo"
      ],
      "metadata": {
        "id": "-Qe5PZiFuYVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import bs4\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pCinAn9vr_gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(web_paths=('https://www.bbc.com/portuguese/articles/cd19vexw0y1o',))\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "ISRPCHfjvQVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs[0].page_content)"
      ],
      "metadata": {
        "id": "wOZZzKd8vyhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(docs[0].page_content[:300])"
      ],
      "metadata": {
        "id": "OAvnbDiswLuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 - Divisão em pedaços de texto / Split"
      ],
      "metadata": {
        "id": "xe1CpK3FudhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "oLpyzt5cundk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(splits)"
      ],
      "metadata": {
        "id": "y52vejI1xcGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits[0]"
      ],
      "metadata": {
        "id": "of9CvFvvxoaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splits[1]"
      ],
      "metadata": {
        "id": "7JywBqMsxq3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 - Armazenamento"
      ],
      "metadata": {
        "id": "3ugs-rcuuofs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-mpnet-base-v2')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4KduNeZouq9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test = 'Um teste apenas'\n",
        "result = hf_embeddings.embed_query(input_test)"
      ],
      "metadata": {
        "id": "BWjn0JuCykQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(result)"
      ],
      "metadata": {
        "id": "Vx0ahEHSyvUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "UGjEVkt1yxHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=splits, embedding=hf_embeddings)  # armazenamento no formato de vetor"
      ],
      "metadata": {
        "id": "TNNaxlGryy37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etapas de Recuperação e geração de texto"
      ],
      "metadata": {
        "id": "d3eVSMZUzec4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 - Configurand o recuperador de texto / Retriever"
      ],
      "metadata": {
        "id": "AXnvYS3p1lTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 6})"
      ],
      "metadata": {
        "id": "qMUHyg6DzOqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 - Geração"
      ],
      "metadata": {
        "id": "CThYNzOu1r4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template_rag"
      ],
      "metadata": {
        "id": "bLjCL4Sc1tzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_rag = PromptTemplate(\n",
        "    input_variables=['pergunta', 'contexto'],\n",
        "    template=template_rag\n",
        ")\n",
        "prompt_rag"
      ],
      "metadata": {
        "id": "JP29hc4q2S_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return '\\n\\n'.join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "4Y-sGb5V2xIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_rag = ({'contexto': retriever | format_docs, 'pergunta': RunnablePassthrough()}\n",
        "             | prompt_rag\n",
        "             | llm\n",
        "             | StrOutputParser())"
      ],
      "metadata": {
        "id": "3EGXGpsn2nmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teste sem RAG\n",
        "chain.invoke('Qual filme ganhou mais orcars na premiação de 2024?')"
      ],
      "metadata": {
        "id": "Y9qCxAXW3Omh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teste com RAG\n",
        "chain_rag.invoke('Qual filme ganhou mais orcars na premiação de 2024?')"
      ],
      "metadata": {
        "id": "98s_qwqM3sKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_rag.invoke('Quem ganhou o prêmio de melhor ator?')"
      ],
      "metadata": {
        "id": "eWRErLt133__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.delete_collection() # todo o contexto será apagado (limpa o banco de dados)"
      ],
      "metadata": {
        "id": "zi5ZfpRz4IZ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}